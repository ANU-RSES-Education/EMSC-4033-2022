{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602c3e32-5dbb-4450-99aa-fe189f9a6b6b",
   "metadata": {},
   "source": [
    "Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40363126-c173-41b9-b514-747fdc4e083f",
   "metadata": {},
   "source": [
    "Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911d5ad-fb3d-4402-8422-005266d44b90",
   "metadata": {},
   "source": [
    "This map is a very simple guide to making a distribution map of an organism.This project uses an open online database (In this map, we use data from gbif)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6ab39-f1c7-49ab-83d7-a8430bb5c979",
   "metadata": {},
   "source": [
    "The project aims to filter and gather organism occurrence data to build a data frame, eventually, converting it to a numpy array and adding it to the basemap. It involves two main components, the API query section and the plotting section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27173c53-bd0a-4274-9875-c4830562297d",
   "metadata": {},
   "source": [
    "First, we need to think an organism and a continent of interest. (as a demonstration, I use platypus distribution in Oceania.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233fe83-7368-4437-9aee-d3e3fdfbffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#platypus distribution in Oceania.\n",
    "name = 'Ornithorhynchus anatinus'\n",
    "region ='Oceania'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738d034-b6d4-409f-b084-fc217b5ce765",
   "metadata": {},
   "source": [
    "For the preparation, we need to set up the basic URL of the database and other parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794fa28-21a0-49e5-a1a2-ca6ebe34b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up\n",
    "#database API URL\n",
    "data_url = \"https://api.gbif.org/v1/occurrence/search?\"\n",
    "#Page parameter 'offset' indicate position and page, initial value set to 0.\n",
    "offset = 0\n",
    "#Page parameter 'limit' means the number of data present in a single page, max limit for gbif is 300.\n",
    "limit = 300\n",
    "#endofRecords indicate if the current page is the last page, when endofRcords= True, we can stop requesting. Set to false to strat with.\n",
    "endOfRecords = False\n",
    "#Create a empty dataframe for our data.\n",
    "df_main = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f11ae-6aec-4665-9929-5ae03c670b11",
   "metadata": {},
   "source": [
    "Next, use the obtain_spKey function to get the speciesKey for that organism, so I only get spatial occurrence data for this species, avoiding relevant but unwanted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffab61a-5d3b-4800-bf29-3b63ccd4c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the speciesKey for platypus, sciencific name 'Ornithorhynchus anatinus'.\n",
    "spKey=obtain_spKey(data_url, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a04ea3-471d-4bdf-8102-0707d92f3aa9",
   "metadata": {},
   "source": [
    "Assemble all parameters we need to make the ultimate URL to request the data. However, the returning data may be too much to fit in a single page (exceed the limit=300), often, we have multiple pages of results in response. Here we have the endofRecord==false loop function to get all the pages until the last. (whenever move to next page, offset would become the last offset + limit.\n",
    "\n",
    "i.e.\n",
    "One first page, offset=0 (the starting position), limit=300\n",
    "One second page, offset=0+limit= 0+300 (the last page contain 300 data, now we are on a new page).\n",
    "One third page, offset=300+limit=300+300 = 600 (now we are at position 600)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b448ecb-f020-4051-92ef-674acba98f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params=(set_up_params(spKey, region, limit))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b37c9f-f42b-4077-bebd-2e6832da8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We send a request to the gbif server, scan and load all the results into our data frame\n",
    "#However, the data might be too much to fit in a single page (exceed the limit=300), often, we have multiple pages of results in response.\n",
    "#Here we have the endofRecord==false loop function to get all the pages until the last.(whenever move to next page, offset would beocome last offset + limit.)\n",
    "while endOfRecords == False:\n",
    "    endOfRecords, df_main= server_scan(data_url, offset, params, df_main)\n",
    "    offset += limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26264e-f658-4baa-b481-ada096b875ba",
   "metadata": {},
   "source": [
    "Now we have a pandas dataframe df_main about matched occurrence data of platypus. Convert it to a csv file preparing for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893ce32-be7c-4c30-870a-11fc405fac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataframe format to csv for easier management.\n",
    "get_csv(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f0d37-a72f-4811-8da4-68fe0e6e59bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Get the corrdinate information we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1a81a-c977-4eb6-a328-651ee74ea8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The results contain lots of information, but we are only interested in coordinates here.\n",
    "df_corrdinate= df_main[['decimalLongitude', 'decimalLatitude']]\n",
    "df_corrdinate.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76177cad-9dd8-4044-a124-9f18fc9fc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "Form a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc5626-d0cc-4ba2-8bb6-224bc444c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot, convert the data to numpy array\n",
    "numpy_array = df_corrdinate.to_numpy()\n",
    "print(numpy_array)\n",
    "print(type(numpy_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb976f0-6c15-403b-9cbd-11b602ea8617",
   "metadata": {},
   "source": [
    "Create a basemap dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f650f2-62ec-477a-b0e9-097df78733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_tiles_dictionary = basemap_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d552a6-3bcc-4bda-bc1c-bd04dd55e04a",
   "metadata": {},
   "source": [
    "Plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285991d3-4574-47b2-ab4c-82f68ab77eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_tiles = map_tiles_dictionary[basemap_name]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12), facecolor=\"none\")\n",
    "\n",
    "# Create a GeoAxes in the tile's projection.\n",
    "# Without it, the lon and lat would not be recogonised.\n",
    "ax = plt.axes(projection=map_tiles.crs)\n",
    "\n",
    "# Set the size of the map\n",
    "ax.set_extent(map_extent)\n",
    "\n",
    "# Add the on-demand image and resolution\n",
    "ax.add_image(map_tiles, 10)\n",
    "\n",
    "#prepartion on load your point data\n",
    "#I transposed the numpy_arrray to make it suitable for plotting\n",
    "oalon, oalat= numpy_array.T\n",
    "\n",
    "#plot point data of organism distribution \n",
    "plt.scatter(oalon, oalat, linewidth=0, c='red', transform=ccrs.PlateCarree(), alpha=0.5, zorder=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1605f5-c362-4ae5-8fd3-365d72d33072",
   "metadata": {},
   "source": [
    "List of dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c50499-0fcf-474c-b659-96ab6d2d01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API query\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "#plotting\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64f530-8550-46cc-9664-4f99d4357acd",
   "metadata": {},
   "source": [
    "For the API requesting part, we need the requests package to send a request to the server, JSON package to format the data, pandas packages to create a data frame, NumPy package to form a plottable array and urlencode to rewrite information to format used for URL.\n",
    "For the plotting part, cartopy package is useful to add base map, axes and data point, and matplotlib.pyplot package actucally does the plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e6ad8-430b-4843-b7c8-7e68f98552d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a17ff4d-10b0-46f1-a001-3b856a7175ad",
   "metadata": {},
   "source": [
    "Describe testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b8063-b2cc-4d66-9a21-b80554bccd23",
   "metadata": {},
   "source": [
    "The testing code is trivial, which only checks if the code returns the expected data type and the number of elements.\n",
    "The information can be double-checked by accessing the gbif database website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d3646-d867-4280-b839-c2317feaeb20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4138e1-52c4-438f-8495-b8aa9a04c7b7",
   "metadata": {},
   "source": [
    "Limitations / Future Improvments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc2f89-b944-42ad-b3ff-cf4d35a792aa",
   "metadata": {},
   "source": [
    "The main limitation would be the overall framework best for gbif database and may not be applicable to other databases using different formatting and structure.\n",
    "The second limitation is the testing, which is too trial and vague. It does not test for some critical parts which may break the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
